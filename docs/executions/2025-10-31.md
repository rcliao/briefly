# Briefly - Implementation Plan (v2.1)

**Date:** 2025-10-31
**Status:** In Progress
**Timeline:** 10 weeks (Nov 2025 - Jan 2026)
**Author:** System Design

## Context

This is the initial implementation plan for transforming Briefly v3.0 (simplified CLI) into a full-featured weekly news digest website (v2.0 product vision). Created after completing design document split and before beginning Phase 0 execution.

**Previous State:** v3.0 simplified architecture with 9-step pipeline, CLI-only interface
**Target State:** Autonomous weekly digest website with multi-agent processing, LangFuse observability, theme-based filtering

This is a **short-lived document** that will be superseded as we complete phases and learn from execution. See `docs/executions/README.md` for lifecycle information.

---

## Table of Contents

1. [Overview](#overview)
2. [Phase 0: Research & Foundation](#phase-0-research--foundation-week-1)
3. [Phase 1: RSS Aggregation with Themes](#phase-1-rss-aggregation-with-themes-week-2)
4. [Phase 2: Search Integration](#phase-2-search-integration-week-3)
5. [Phase 3: RAG & Advanced Processing](#phase-3-rag--advanced-processing-weeks-4-5)
6. [Phase 4: Evaluation Framework](#phase-4-evaluation-framework-week-6)
7. [Phase 5: Web Interface](#phase-5-web-interface-weeks-7-8)
8. [Phase 6: Automation](#phase-6-automation-week-9)
9. [Phase 7: Polish & Deploy](#phase-7-polish--deploy-week-10)
10. [Timeline Summary](#timeline-summary)
11. [Dependencies & Risks](#dependencies--risks)

---

## Overview

This document outlines the 10-week implementation plan for transforming Briefly from a CLI-based digest generator into an autonomous, weekly-updating news digest website with multi-agent architecture, LangFuse observability, and theme-based personalization.

**Key Principles:**
- Build incrementally with testable milestones
- Integrate observability (LangFuse) from Phase 0
- Prioritize high-value features first (RSS, themes, structured summaries)
- Keep search and RAG as separate, optional phases
- Deploy early (Phase 7) to gather real user feedback

---

## Phase 0: Research & Foundation (Week 1)

### Goal
Set up foundational infrastructure and core features needed for all subsequent phases.

### Completed
- âœ… Kagi News research and design document creation
- âœ… v2.1 design document with all editorial changes
- âœ… Split design into modular documents (Product, Inspiration, Architecture, Execution)

### To Do

#### 1. LangFuse Setup (2 days)
- [ ] Sign up for LangFuse Cloud or self-host
- [ ] Install Go SDK: `go get github.com/langfuse/langfuse-go`
- [ ] Instrument existing LLM calls (summarization, categorization)
- [ ] Verify traces appear in dashboard
- [ ] Configure prompt versioning
- [ ] Test trace linking (sessions, users)

**Acceptance Criteria:**
- All Gemini API calls traced in LangFuse
- Cost and latency visible per LLM operation
- Prompts versioned and retrievable

#### 2. PostHog Setup (1 day)
- [ ] Sign up for PostHog Cloud or self-host
- [ ] Add frontend snippet to HTML templates
- [ ] Install Go SDK: `go get github.com/posthog/posthog-go`
- [ ] Define key events to track:
  - Page views (digest, article)
  - Digest generation completed
  - Theme filtering
  - Article click-through
- [ ] Create initial dashboard in PostHog UI

**Acceptance Criteria:**
- Page views tracked automatically
- Backend events sent to PostHog
- Dashboard shows basic metrics

#### 3. Theme System (2 days)
- [ ] Create `themes` table with migration
- [ ] Implement `ThemeRepository` (CRUD operations)
- [ ] Build `LLMThemeClassifier` with LangFuse tracing
- [ ] CLI commands:
  - `briefly theme list` - List all themes
  - `briefly theme add GenAI "AI, ML, LLMs"` - Create theme
  - `briefly theme edit GenAI --keywords "..."` - Update theme
- [ ] Seed default themes (GenAI, Gaming, Technology)
- [ ] Write unit tests for repository and classifier

**Acceptance Criteria:**
- Themes CRUD works via CLI
- LLM can classify articles by theme with relevance score
- LangFuse shows classification traces

#### 4. Manual URL Submission (2 days)
- [ ] Create `manual_urls` table with migration
- [ ] Implement `ManualURLRepository`
- [ ] CLI commands:
  - `briefly add-url https://example.com` - Add single URL
  - `briefly add-urls urls.txt` - Batch add from file
  - `briefly list-manual-urls` - Show pending URLs
- [ ] Web admin form (simple HTML + HTMX)
- [ ] Batch upload (text/CSV file)
- [ ] Integration with pipeline (manual URLs treated like RSS)
- [ ] Write unit tests

**Acceptance Criteria:**
- Can add URLs via CLI and web
- URLs integrated into digest pipeline
- Manual URLs processed like RSS content

### Deliverables
- âœ… LangFuse tracking all LLM operations
- âœ… PostHog tracking basic page views
- âœ… Working theme classification system
- âœ… Manual URL submission (CLI + Web)

---

## Phase 1: RSS Aggregation with Themes (Week 2)

### Goal
RSS content aggregation with theme-based filtering and structured summaries.

### Tasks

#### 1. Enhanced RSS Aggregation (3 days)
- [ ] Refactor `aggregate.go` to use theme classification
- [ ] Add relevance scoring per article (0.0-1.0 scale)
- [ ] Filter low-relevance articles (configurable threshold)
- [ ] LangFuse instrumentation for classification calls
- [ ] CLI: `briefly aggregate --theme GenAI --min-relevance 0.7`
- [ ] Update tests

**Acceptance Criteria:**
- RSS feeds classified by theme automatically
- Low-relevance articles filtered out
- LangFuse shows classification performance

#### 2. Structured Summary Generation (3 days)
- [ ] Update `summaries` table schema (add structured fields)
- [ ] Implement `StructuredSummarizer` using Gemini structured output API
- [ ] Define schema:
  ```go
  type StructuredSummary struct {
      Summary      string   `json:"summary"`
      KeyMoments   []string `json:"key_moments"`
      Perspectives []string `json:"perspectives"`
      WhyImportant string   `json:"why_important"`
      Context      string   `json:"context"`
  }
  ```
- [ ] Use Gemini `response_schema` parameter (no JSON parsing!)
- [ ] LangFuse tracking per section generated
- [ ] Write unit tests for structured output

**Acceptance Criteria:**
- Summaries generated with all 5 sections
- No JSON parsing errors (using structured output API)
- LangFuse shows section-level metrics

#### 3. Citation Tracking (1 day)
- [ ] Create `citations` table with migration
- [ ] Implement `CitationTracker` component
- [ ] Link citations to summaries during processing
- [ ] Update API responses to include citations
- [ ] Write unit tests

**Acceptance Criteria:**
- Citations stored with metadata (URL, title, publisher, date)
- API returns citations alongside summaries

### Deliverables
- âœ… RSS feeds automatically classified by theme
- âœ… Low-relevance articles filtered out
- âœ… Structured summaries with all sections (Key Moments, Perspectives, Why It Matters)
- âœ… Citations tracked and retrievable

---

## Phase 2: Search Integration (Week 3) - SEPARATE FEATURE

### Goal
Web search as additional content source (optional, can be skipped).

### Tasks

#### 1. Search Client Implementation (3 days)
- [ ] Create `internal/search/` package
- [ ] Implement Google Custom Search client
- [ ] Implement Bing Search client (fallback)
- [ ] Query builder with LLM query generation
- [ ] Result deduplication and filtering
- [ ] Write unit tests

#### 2. Search Query Management (2 days)
- [ ] Create `search_queries` table
- [ ] Implement `SearchQueryRepository`
- [ ] CLI commands:
  - `briefly search add "GenAI releases"` - Add query
  - `briefly search list` - Show all queries
  - `briefly search test "query"` - Test search results
- [ ] Web admin UI for search queries
- [ ] Write tests

#### 3. Integration with Pipeline (2 days)
- [ ] Add SearchWorker agent
- [ ] Integrate with aggregation command
- [ ] CLI: `briefly aggregate --source search`
- [ ] Theme classification for search results
- [ ] LangFuse tracking for search operations
- [ ] Write integration tests

### Deliverables
- âœ… Google/Bing search integration
- âœ… Search queries configurable via CLI/Web
- âœ… Search results classified and filtered by theme
- âœ… All search operations tracked in LangFuse

**Note:** This phase can be deferred if RSS and manual URLs provide sufficient content.

---

## Phase 3: RAG & Advanced Processing (Weeks 4-5)

### Goal
Vector search and context-aware processing for improved classification consistency.

### Tasks

#### 1. pgvector Setup (2 days)
- [ ] Install pgvector extension on PostgreSQL:
  ```sql
  CREATE EXTENSION IF NOT EXISTS vector;
  ```
- [ ] Create `article_embeddings` table with vector column
- [ ] Create IVFFlat or HNSW index for fast similarity search
- [ ] Test similarity search performance (<100ms target)
- [ ] Write migration scripts

**Acceptance Criteria:**
- Similarity search working with <100ms latency
- Index created and optimized

#### 2. RAG Retriever (3 days)
- [ ] Create `internal/rag/` package
- [ ] Implement `VectorStore` interface with pgvector backend
- [ ] Implement `Retriever` with theme filtering
- [ ] Context builder for different use cases:
  - Article classification context
  - Summary generation context
  - Cluster labeling context
- [ ] Write unit tests

#### 3. RAG Integration (3 days)
- [ ] Update summarization to include RAG context
- [ ] RAG-enhanced theme classification
- [ ] RAG-based cluster labeling
- [ ] Measure accuracy improvement with evals
- [ ] LangFuse tracking for RAG retrievals
- [ ] Write integration tests

**Acceptance Criteria:**
- RAG context retrieved and used in LLM calls
- Measurable improvement in classification consistency (>15%)
- LangFuse shows RAG retrieval metrics

### Deliverables
- âœ… Working pgvector similarity search
- âœ… RAG context used in summarization and classification
- âœ… Measurable improvement in consistency (eval scores)

---

## Phase 4: Evaluation Framework (Week 6)

### Goal
CLI-based prompt evaluation system for continuous improvement.

### Tasks

#### 1. Dataset Management (2 days)
- [ ] Create `eval_datasets` and `eval_examples` tables
- [ ] Implement `DatasetManager`
- [ ] CLI commands:
  - `briefly eval dataset create summarization` - Create dataset
  - `briefly eval dataset add summarization example.json` - Add example
  - `briefly eval dataset list` - List all datasets
- [ ] JSONL file import for bulk examples
- [ ] Write tests

#### 2. LLM Judge (2 days)
- [ ] Implement `LLMJudge` with evaluation criteria
- [ ] Create judge prompts:
  - Summarization quality (accuracy, conciseness, relevance)
  - Classification accuracy (theme matching)
- [ ] Structured JSON output parsing
- [ ] LangFuse integration for eval runs
- [ ] Write tests

#### 3. Evaluation Runner (2 days)
- [ ] Implement `EvalRunner`
- [ ] CLI commands:
  - `briefly eval run --dataset summarization --prompt v1` - Run eval
  - `briefly eval compare v1 v2` - Compare prompts
- [ ] Generate evaluation reports (Markdown format)
- [ ] Cost tracking per eval run
- [ ] Write integration tests

**Acceptance Criteria:**
- Can run evals against golden datasets
- Prompt comparison shows score differences
- Markdown reports generated

#### 4. Golden Dataset Creation (1 day)
- [ ] Manually label 50+ examples for summarization
- [ ] Label 30+ examples for theme classification
- [ ] Document evaluation rubrics
- [ ] Store in `examples/` directory

### Deliverables
- âœ… CLI-based evaluation framework
- âœ… 100+ labeled examples across tasks
- âœ… Ability to compare prompts and track improvements
- âœ… Evaluation runs linked to LangFuse

---

## Phase 5: Web Interface (Weeks 7-8)

### Goal
Public digest viewer + admin dashboard.

### Tasks

#### 1. Frontend Setup (2 days)
- [ ] Set up TailwindCSS (CDN or PostCSS)
- [ ] Configure HTMX for interactive components
- [ ] Create base HTML templates (layout, navigation)
- [ ] Implement static file serving
- [ ] Add PostHog snippet to all pages

#### 2. Public Pages (4 days)
- [ ] Homepage (`/`) - Latest digest with theme selector
- [ ] Digest viewer (`/digests/{date}`) - Structured sections display
- [ ] Article detail page (`/articles/{id}`) - Full content + citations
- [ ] Article browser (`/articles`) - Search/filter UI
- [ ] Past digests archive (`/digests`) - Paginated list
- [ ] Theme filter component (HTMX live updates)

#### 3. Admin Pages (4 days)
- [ ] Admin dashboard (`/admin`) - Overview stats
- [ ] RSS feed management (`/admin/feeds`) - CRUD UI
- [ ] Theme management (`/admin/themes`) - CRUD UI
- [ ] Manual URL submission (`/admin/urls`) - Form + batch upload
- [ ] Search query management (`/admin/search`) - CRUD UI
- [ ] Configuration editor (`/admin/config`) - Key-value pairs

#### 4. API Handler Implementation (3 days)
- [ ] Complete all handlers in `internal/server/handlers.go`
- [ ] Add pagination, filtering, sorting to list endpoints
- [ ] Proper error handling (JSON responses)
- [ ] Write integration tests for all endpoints

#### 5. PostHog Analytics Integration (1 day)
- [ ] Add event tracking to frontend:
  - Page views
  - Article clicks
  - Theme filter changes
  - Digest downloads
- [ ] Add backend events:
  - Digest generation completed
  - Article processing stats
- [ ] Create initial PostHog dashboard
- [ ] Test events in PostHog UI

**Acceptance Criteria:**
- Public can view digests without authentication
- Admin can manage all sources and configurations
- PostHog tracking all user interactions

### Deliverables
- âœ… Fully functional web interface
- âœ… Public can view digests with theme filtering
- âœ… Admin can manage all sources and configurations
- âœ… PostHog tracking user engagement

---

## Phase 6: Automation (Week 9)

### Goal
Weekly automated digest generation with configurable scheduling.

### Tasks

#### 1. Manual CLI Commands (2 days)
- [ ] Ensure all pipeline steps runnable independently:
  - `briefly aggregate` - Fetch from all sources
  - `briefly classify` - Theme classification
  - `briefly summarize` - Generate summaries
  - `briefly cluster` - Topic clustering
  - `briefly digest generate --theme GenAI` - Full pipeline
- [ ] Add `--dry-run` flag for cost estimation
- [ ] Write comprehensive CLI documentation

#### 2. Optional: In-App Scheduler (2 days)
- [ ] Implement `CronScheduler` using `robfig/cron`
- [ ] Define jobs:
  - Aggregation job
  - Processing job
  - Digest generation job
- [ ] CLI: `briefly serve --with-scheduler`
- [ ] Job status tracking in database
- [ ] Write tests

#### 3. Infrastructure CRON Setup (1 day)
- [ ] Document infrastructure-level CRON approach
- [ ] Example crontab entries:
  ```bash
  # Daily digest at 9am
  0 9 * * * cd /app && ./briefly digest generate --daily

  # Weekly digest every Monday at 9am
  0 9 * * 1 cd /app && ./briefly digest generate --weekly
  ```
- [ ] Systemd timer examples (if VPS deployment)
- [ ] Railway/Fly.io scheduled job examples

#### 4. Email Distribution (Optional) (2 days)
- [ ] Reuse existing `internal/email/` templates
- [ ] SMTP client setup (SendGrid, Mailgun, etc.)
- [ ] CLI: `briefly send-digest --email user@example.com`
- [ ] Batch email sending for subscriber list
- [ ] Write tests

**Acceptance Criteria:**
- Can run full digest pipeline via single command
- CRON setup documented (infrastructure or in-app)
- Email distribution working (optional)

### Deliverables
- âœ… All pipeline steps runnable manually via CLI
- âœ… Choice of in-app or infrastructure-level CRON
- âœ… Optional email distribution
- âœ… Documentation for automation setup

---

## Phase 7: Polish & Deploy (Week 10+)

### Goal
Production deployment and documentation.

### Tasks

#### 1. Deployment Preparation (3 days)
- [ ] Dockerfile for containerization
- [ ] Docker Compose for local development
- [ ] Environment configuration for production (`.env.example`)
- [ ] Health check endpoints (`/health`, `/ready`)
- [ ] Database migration scripts

#### 2. Infrastructure Setup (2 days)
- [ ] Set up PostgreSQL hosting with pgvector:
  - Supabase (has pgvector support)
  - Neon (supports pgvector)
  - Self-hosted PostgreSQL 15+
- [ ] Deploy to Railway/Fly.io
- [ ] Configure domain and SSL
- [ ] Set environment variables:
  - `GEMINI_API_KEY`
  - `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`
  - `POSTHOG_API_KEY`
  - `DATABASE_URL`
- [ ] Verify LangFuse/PostHog connections

#### 3. Documentation (3 days)
- [ ] Update README with:
  - Deployment instructions
  - Environment variable reference
  - CLI command reference
- [ ] API documentation (OpenAPI/Swagger spec)
- [ ] Admin user guide (how to configure sources/themes)
- [ ] Architecture diagrams (update with final state)
- [ ] Code documentation (godoc for all packages)

#### 4. Performance Optimization (2 days)
- [ ] Database query optimization (EXPLAIN ANALYZE)
- [ ] Add database indexes where needed
- [ ] Caching strategy review
- [ ] Memory profiling (`pprof`)
- [ ] Load testing with realistic data

#### 5. Testing & Monitoring (2 days)
- [ ] End-to-end testing on production
- [ ] Load testing (simulate 100+ articles/week)
- [ ] Verify LangFuse traces in production
- [ ] Verify PostHog events in production
- [ ] Set up backup strategy for database
- [ ] Set up error monitoring (Sentry or similar)

**Acceptance Criteria:**
- Production deployment accessible at public URL
- LangFuse and PostHog dashboards showing live data
- Performance targets met (<500ms API p95)
- Complete documentation for new contributors

### Deliverables
- âœ… Production deployment at public URL
- âœ… Complete documentation
- âœ… LangFuse and PostHog dashboards live
- âœ… Performance optimized for 100+ articles/week

---

## Timeline Summary

| Phase | Duration | Key Deliverables | Status |
|-------|----------|------------------|--------|
| Phase 0 | Week 1 | LangFuse, PostHog, Themes, Manual URLs | ðŸŸ¡ In Progress |
| Phase 1 | Week 2 | RSS + Themes, Structured Summaries, Citations | âšª Pending |
| Phase 2 | Week 3 | Search Integration (Optional) | âšª Pending |
| Phase 3 | Weeks 4-5 | RAG with pgvector | âšª Pending |
| Phase 4 | Week 6 | Evaluation Framework | âšª Pending |
| Phase 5 | Weeks 7-8 | Web Interface + Admin | âšª Pending |
| Phase 6 | Week 9 | Automation + CRON | âšª Pending |
| Phase 7 | Week 10+ | Deployment + Polish | âšª Pending |

**Total Timeline:** 10+ weeks (2.5 months)

**Critical Path:**
1. Phase 0 (foundation) â†’ Phase 1 (core features) â†’ Phase 5 (web UI) â†’ Phase 7 (deploy)
2. Phases 2, 3, 4, 6 can be done in parallel or deferred based on priorities

---

## Dependencies & Risks

### External Dependencies
- **LangFuse Cloud/Self-hosted** - Required for Phase 0
- **PostHog Cloud/Self-hosted** - Required for Phase 0
- **PostgreSQL with pgvector** - Required for Phase 3
- **Gemini API** - Already integrated
- **Google/Bing Search API** - Optional (Phase 2)

### Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| LangFuse integration complexity | Medium | Medium | Start with simple traces, iterate |
| pgvector performance at scale | Medium | High | Test with realistic data, optimize indexes |
| LLM cost overruns | Medium | Medium | Implement cost tracking, dry-run mode |
| Search API rate limits | Low | Medium | Cache results, use multiple providers |
| Structured output API changes | Low | High | Version prompts in LangFuse |

### Scope Risks

**Feature Creep Prevention:**
- Phase 2 (Search) is optional - can be deferred
- Phase 6 (Email) is optional - CRON automation is sufficient
- Keep Phase 5 (Web UI) minimal - iterate based on PostHog data

**Success Criteria for MVP (Phase 0-1 + 5 + 7):**
- âœ… RSS feeds with theme filtering
- âœ… Structured summaries with citations
- âœ… Web interface for viewing digests
- âœ… LangFuse observability
- âœ… PostHog analytics
- âœ… Production deployment

---

## Next Steps

**Immediate Actions (Next 3 Days):**
1. âœ… Complete design document split (Product, Inspiration, Architecture, Execution)
2. [ ] Set up LangFuse account and obtain API keys
3. [ ] Set up PostHog account and obtain API key
4. [ ] Implement `themes` table and repository
5. [ ] Implement `manual_urls` table and repository
6. [ ] Write CLI commands for theme and URL management

**Week 1 Goal:**
Complete Phase 0 with all foundation infrastructure ready for Phase 1.

---

## Version History

**v2.1 (2025-10-31):**
- Extracted from main design document
- Added detailed task breakdowns per phase
- Added timeline summary and dependencies
- Structured as short-lived execution document
