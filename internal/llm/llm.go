package llm

import (
	"briefly/internal/core"
	"context"
	"fmt"
	"math"
	"os" // Added to fetch API key from environment variable
	"strings"
	"time"

	"github.com/google/generative-ai-go/genai"
	"github.com/spf13/viper"
	"google.golang.org/api/option"
)

const (
	// DefaultModel is the default Gemini model to use for summarization.
	DefaultModel = "gemini-1.5-flash-latest" // As requested
	// DefaultEmbeddingModel is the default model for generating embeddings
	DefaultEmbeddingModel = "text-embedding-004"
	// SummarizeTextPromptTemplate is the template for the summarization prompt.
	SummarizeTextPromptTemplate = "Please summarize the following text concisely:\n\n---\n%s\n---"
	// SummarizeTextWithFormatPromptTemplate is the template for format-aware summarization.
	SummarizeTextWithFormatPromptTemplate = `Please summarize the following text for a %s digest format.

FORMAT GUIDELINES:
- Brief: Create a very concise summary (50-100 words) focusing only on the most essential information
- Standard: Provide a balanced summary (100-200 words) with key points and context
- Detailed: Generate a comprehensive summary (200-300 words) with thorough analysis and context
- Newsletter: Write an engaging summary (150-250 words) in a conversational, shareable style

Please tailor your summary to match the %s format characteristics.

---
%s
---`
)

// Client represents a client for interacting with an LLM.
// It can be expanded to include more configuration or methods.
type Client struct {
	apiKey     string
	modelName  string
	gClient    *genai.Client          // Store the main client
	genaiModel *genai.GenerativeModel // Store the model for reuse
}

// NewClient creates a new LLM client.
// It supports multiple ways to get the API key (in order of preference):
// 1. Environment variable: GEMINI_API_KEY
// 2. Viper configuration: gemini.api_key
func NewClient(modelName string) (*Client, error) {
	// Try to get API key from multiple sources
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		apiKey = viper.GetString("gemini.api_key")
	}
	if apiKey == "" {
		return nil, fmt.Errorf("Gemini API key not found. Set GEMINI_API_KEY environment variable or configure gemini.api_key in config file")
	}

	// Get model name from parameter, viper config, or default
	if modelName == "" {
		modelName = viper.GetString("gemini.model")
		if modelName == "" {
			modelName = DefaultModel
		}
	}

	ctx := context.Background()
	gClient, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return nil, fmt.Errorf("failed to create Gemini client: %w", err)
	}

	model := gClient.GenerativeModel(modelName)

	return &Client{
		apiKey:     apiKey,
		modelName:  modelName,
		gClient:    gClient,
		genaiModel: model,
	}, nil
}

// SummarizeArticleText takes an Article object, extracts its CleanedText,
// and returns a Summary object.
func (c *Client) SummarizeArticleText(article core.Article) (core.Summary, error) {
	if article.CleanedText == "" {
		return core.Summary{}, fmt.Errorf("article ID %s has no CleanedText to summarize", article.ID)
	}

	prompt := fmt.Sprintf(SummarizeTextPromptTemplate, article.CleanedText)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return core.Summary{}, fmt.Errorf("failed to generate content for article ID %s: %w", article.ID, err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return core.Summary{}, fmt.Errorf("no content generated by the API for article ID %s", article.ID)
	}

	summaryPart := resp.Candidates[0].Content.Parts[0]
	summaryText, ok := summaryPart.(genai.Text)
	if !ok {
		return core.Summary{}, fmt.Errorf("unexpected response format from API for article ID %s, expected genai.Text", article.ID)
	}

	// Populate the Summary struct
	// ID for summary can be generated, or based on article ID if 1:1
	// For now, let's assume a new UUID for summary would be generated elsewhere or not strictly needed yet.
	summary := core.Summary{
		// ID: will be set by the caller or a storage layer
		ArticleIDs:  []string{article.ID},
		SummaryText: string(summaryText),
		ModelUsed:   c.modelName,
		// Instructions: Could be the prompt template, or a more abstract description
		Instructions: SummarizeTextPromptTemplate, // Or a reference to it
		// DateGenerated: time.Now().UTC(), // This should be set when the summary is finalized
	}

	return summary, nil
}

// SummarizeArticleTextWithFormat takes an Article object, extracts its CleanedText,
// and returns a Summary object with format-specific guidance.
func (c *Client) SummarizeArticleTextWithFormat(article core.Article, format string) (core.Summary, error) {
	if article.CleanedText == "" {
		return core.Summary{}, fmt.Errorf("article ID %s has no CleanedText to summarize", article.ID)
	}

	prompt := fmt.Sprintf(SummarizeTextWithFormatPromptTemplate, format, format, article.CleanedText)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return core.Summary{}, fmt.Errorf("failed to generate content for article ID %s: %w", article.ID, err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return core.Summary{}, fmt.Errorf("no content generated by the API for article ID %s", article.ID)
	}

	summaryPart := resp.Candidates[0].Content.Parts[0]
	summaryText, ok := summaryPart.(genai.Text)
	if !ok {
		return core.Summary{}, fmt.Errorf("unexpected response format from API for article ID %s, expected genai.Text", article.ID)
	}

	// Populate the Summary struct
	summary := core.Summary{
		ArticleIDs:   []string{article.ID},
		SummaryText:  string(summaryText),
		ModelUsed:    c.modelName,
		Instructions: fmt.Sprintf("Format-aware summarization for %s format", format),
	}

	return summary, nil
}

// SummarizeArticleWithKeyMoments creates a summary with key moments in a specific format
func (c *Client) SummarizeArticleWithKeyMoments(article core.Article) (core.Summary, error) {
	if article.CleanedText == "" {
		return core.Summary{}, fmt.Errorf("article ID %s has no CleanedText to summarize", article.ID)
	}

	// Custom prompt for summary with key moments
	keyMomentsPrompt := `Please analyze the following article and provide a summary in this exact format:

# Executive Summary

[Write a concise 2-3 sentence summary that captures the main topic and key takeaway]

# Key Insights

## üí° [Short descriptive title for first insight]
> "[Select a powerful, concise quote (1-2 sentences max) from the article]"

**Why it matters:** [One clear sentence explaining the significance]

## üìä [Short descriptive title for second insight] 
> "[Another impactful quote from the article]"

**Why it matters:** [One clear sentence explaining the significance]

## üöÄ [Short descriptive title for third insight]
> "[Another important quote from the article]"

**Why it matters:** [One clear sentence explaining the significance]

## üîç [Short descriptive title for fourth insight]
> "[Final key quote from the article]"

**Why it matters:** [One clear sentence explaining the significance]

Instructions:
- Use EXACT, concise quotes (1-2 sentences maximum) from the article
- Create descriptive titles that categorize each insight (e.g., "Performance Breakthrough", "New Feature Launch", "Market Impact")
- Keep explanations to one clear, punchy sentence
- Use appropriate emojis for insight categories: üí° (concepts), üìä (data/metrics), üöÄ (launches/features), üîç (analysis), ‚ö° (speed/performance), üîí (security/privacy), üí∞ (business/cost)
- Select 3-4 most impactful moments that represent different aspects of the story

Article Content:
%s`

	prompt := fmt.Sprintf(keyMomentsPrompt, article.CleanedText)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return core.Summary{}, fmt.Errorf("failed to generate content for article ID %s: %w", article.ID, err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return core.Summary{}, fmt.Errorf("no content generated by the API for article ID %s", article.ID)
	}

	summaryPart := resp.Candidates[0].Content.Parts[0]
	summaryText, ok := summaryPart.(genai.Text)
	if !ok {
		return core.Summary{}, fmt.Errorf("unexpected response format from API for article ID %s, expected genai.Text", article.ID)
	}

	// Create the Summary object
	summary := core.Summary{
		ArticleIDs:    []string{article.ID},
		SummaryText:   string(summaryText),
		ModelUsed:     c.modelName,
		Instructions:  "Article summarization with key moments and explanations",
		DateGenerated: time.Now().UTC(),
	}

	return summary, nil
}

// Close cleans up resources used by the client
func (c *Client) Close() {
	if c.gClient != nil {
		c.gClient.Close()
	}
}

// GenerateSummary is a simpler function, more aligned with the original request,
// that takes text and returns a summary string.
// It uses the GEMINI_API_KEY environment variable and the default model.
func GenerateSummary(textContent string) (string, error) {
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		return "", fmt.Errorf("GEMINI_API_KEY environment variable not set")
	}

	ctx := context.Background()
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return "", fmt.Errorf("failed to create Gemini client: %w", err)
	}
	defer client.Close()

	model := client.GenerativeModel(DefaultModel)
	prompt := fmt.Sprintf(SummarizeTextPromptTemplate, textContent)

	resp, err := model.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate content for summarization: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no content generated by the API for summarization")
	}

	summaryPart := resp.Candidates[0].Content.Parts[0]
	summary, ok := summaryPart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for summarization, expected genai.Text")
	}

	return string(summary), nil
}

// RegenerateDigestWithMyTake takes an existing digest and a personal take,
// then uses the LLM to regenerate the entire digest incorporating the personal perspective throughout
func RegenerateDigestWithMyTake(digestContent, myTake, format string) (string, error) {
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		return "", fmt.Errorf("GEMINI_API_KEY environment variable not set")
	}

	ctx := context.Background()
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return "", fmt.Errorf("failed to create Gemini client: %w", err)
	}
	defer client.Close()

	model := client.GenerativeModel(DefaultModel)

	// Create a sophisticated prompt that asks the LLM to rewrite the digest
	// incorporating the personal perspective throughout
	prompt := fmt.Sprintf(`You are helping to rewrite a digest to incorporate the author's personal perspective throughout the content. 

Here is the original digest:
---
%s
---

Here is the author's personal take/perspective:
---
%s
---

Please rewrite the entire digest incorporating the author's personal voice and perspective throughout. The goal is to:

1. Maintain all the factual information and structure from the original digest
2. Weave the author's perspective naturally throughout the content (not just at the end)
3. Use the author's voice and tone based on their "take"
4. Keep the same format (%s) but make it feel like the author wrote it with their personal insights
5. Make it feel cohesive and natural, not like separate sections were bolted together
6. Preserve any important details, links, and key insights from the original
7. The result should feel like the author's personal commentary and analysis of the topics

Do not add a separate "My Take" section - instead, integrate the perspective throughout the entire digest naturally.

Please provide the complete rewritten digest:`, digestContent, myTake, format)

	resp, err := model.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate content for digest regeneration: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no content generated by the API for digest regeneration")
	}

	contentPart := resp.Candidates[0].Content.Parts[0]
	content, ok := contentPart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for digest regeneration, expected genai.Text")
	}

	return string(content), nil
}

// GeneratePromptCorner generates interesting prompts based on digest content
// that readers can copy and use with any LLM (ChatGPT, Gemini, Claude, etc.)
func GeneratePromptCorner(digestContent string) (string, error) {
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		return "", fmt.Errorf("GEMINI_API_KEY environment variable not set")
	}

	ctx := context.Background()
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return "", fmt.Errorf("failed to create Gemini client: %w", err)
	}
	defer client.Close()

	model := client.GenerativeModel(DefaultModel)

	prompt := fmt.Sprintf(`Based on the following digest content, create at most 3 interesting and practical prompts that readers can copy and paste into any LLM (ChatGPT, Gemini, Claude, etc.). 

The prompts should be:
- Directly inspired by the topics covered in the digest
- Practical and actionable for developers, tech professionals, or curious learners
- Self-contained (no need for additional context)
- Simple to copy and paste
- Encouraging exploration and learning

Format the output as a clean markdown section with:
- A brief intro sentence
- Each prompt in a code block for easy copying
- A short description after each prompt explaining what it's for

Here's the digest content:
---
%s
---

Please generate the Prompt Corner section:`, digestContent)

	resp, err := model.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate content for prompt corner: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no content generated by the API for prompt corner")
	}

	contentPart := resp.Candidates[0].Content.Parts[0]
	content, ok := contentPart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for prompt corner, expected genai.Text")
	}

	return string(content), nil
}

// GenerateDigestTitle creates a compelling title for a digest based on the content
func (c *Client) GenerateDigestTitle(digestContent string, format string) (string, error) {
	if digestContent == "" {
		return "", fmt.Errorf("cannot generate title for empty digest content")
	}

	// Create a prompt that asks for a compelling title based on the digest content
	prompt := fmt.Sprintf(`Generate a compelling and concise title for the following digest content. The title MUST primarily reflect the core substance, main themes, and key insights of the digest. It should be engaging, informative, and under 80 characters. As a secondary consideration, ensure the tone aligns with a '%s' format style (e.g., Brief: direct; Standard: informative; Detailed: analytical; Newsletter: engaging/shareable).

DIGEST CONTENT:
---
%s
---

Generate only the title text, without any markdown formatting or additional text:`, format, digestContent)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate title: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no title generated by the API")
	}

	titlePart := resp.Candidates[0].Content.Parts[0]
	title, ok := titlePart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for title generation, expected genai.Text")
	}

	// Clean up the title - remove any unwanted characters or formatting
	titleStr := strings.TrimSpace(string(title))
	titleStr = strings.Trim(titleStr, "\"'") // Remove quotes if present

	return titleStr, nil
}

// GenerateDigestTitle creates a compelling title for a digest based on the content
// It uses the GEMINI_API_KEY environment variable and the default model.
func GenerateDigestTitle(digestContent string, format string) (string, error) {
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		return "", fmt.Errorf("GEMINI_API_KEY environment variable not set")
	}

	ctx := context.Background()
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return "", fmt.Errorf("failed to create Gemini client: %w", err)
	}
	defer client.Close()

	model := client.GenerativeModel(DefaultModel)

	// Create a prompt that asks for a compelling title based on the digest content
	prompt := fmt.Sprintf(`Generate a compelling and concise title for the following digest content. The title MUST primarily reflect the core substance, main themes, and key insights of the digest. It should be engaging, informative, and under 80 characters. As a secondary consideration, ensure the tone aligns with a '%s' format style (e.g., Brief: direct; Standard: informative; Detailed: analytical; Newsletter: engaging/shareable).

DIGEST CONTENT:
---
%s
---

Generate only the title text, without any markdown formatting or additional text:`, digestContent)

	resp, err := model.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate title: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no title generated by the API")
	}

	titlePart := resp.Candidates[0].Content.Parts[0]
	title, ok := titlePart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for title generation, expected genai.Text")
	}

	// Clean up the title - remove any unwanted characters or formatting
	titleStr := strings.TrimSpace(string(title))
	titleStr = strings.Trim(titleStr, "\"'") // Remove quotes if present

	return titleStr, nil
}

// GenerateEmbedding generates a vector embedding for the given text using Gemini's embedding model
func (c *Client) GenerateEmbedding(text string) ([]float64, error) {
	ctx := context.Background()

	// Use the embedding model specifically for embeddings
	embeddingModel := c.gClient.EmbeddingModel(DefaultEmbeddingModel)

	resp, err := embeddingModel.EmbedContent(ctx, genai.Text(text))
	if err != nil {
		return nil, fmt.Errorf("failed to generate embedding: %w", err)
	}

	if resp.Embedding == nil || resp.Embedding.Values == nil {
		return nil, fmt.Errorf("no embedding values returned from API")
	}

	// Convert float32 to float64
	embedding := make([]float64, len(resp.Embedding.Values))
	for i, val := range resp.Embedding.Values {
		embedding[i] = float64(val)
	}

	return embedding, nil
}

// GenerateEmbeddingForArticle generates an embedding for an article's content
func (c *Client) GenerateEmbeddingForArticle(article core.Article) ([]float64, error) {
	// Combine title and content for better embedding representation
	text := article.Title + "\n\n" + article.CleanedText

	// Truncate if text is too long (embedding models have token limits)
	if len(text) > 8000 { // Conservative limit for text-embedding-004
		text = text[:8000]
	}

	return c.GenerateEmbedding(text)
}

// GenerateEmbeddingForSummary generates an embedding for a summary's content
func (c *Client) GenerateEmbeddingForSummary(summary core.Summary) ([]float64, error) {
	return c.GenerateEmbedding(summary.SummaryText)
}

// CosineSimilarity calculates the cosine similarity between two embeddings
func CosineSimilarity(a, b []float64) float64 {
	if len(a) != len(b) {
		return 0
	}

	var dotProduct, normA, normB float64
	for i := range a {
		dotProduct += a[i] * b[i]
		normA += a[i] * a[i]
		normB += b[i] * b[i]
	}

	if normA == 0 || normB == 0 {
		return 0
	}

	return dotProduct / (math.Sqrt(normA) * math.Sqrt(normB))
}

// GenerateResearchQueries generates search queries for deep research based on article content
func (c *Client) GenerateResearchQueries(article core.Article, depth int) ([]string, error) {
	if article.CleanedText == "" {
		return nil, fmt.Errorf("article ID %s has no CleanedText for research query generation", article.ID)
	}

	prompt := fmt.Sprintf(`Based on the following article, generate %d highly specific and targeted search queries that would help discover related content, background information, and follow-up research. 

The queries should be:
- Specific enough to find relevant, high-quality sources
- Diverse in perspective (technical, business, historical, competitive analysis)
- Actionable for someone researching this topic further
- Not too broad or generic

Article Title: %s

Article Content:
%s

Return the queries as a simple numbered list (1. Query one 2. Query two, etc.) without any additional formatting:`, depth, article.Title, article.CleanedText)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return nil, fmt.Errorf("failed to generate research queries for article ID %s: %w", article.ID, err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return nil, fmt.Errorf("no queries generated by the API for article ID %s", article.ID)
	}

	queriesPart := resp.Candidates[0].Content.Parts[0]
	queriesText, ok := queriesPart.(genai.Text)
	if !ok {
		return nil, fmt.Errorf("unexpected response format from API for article ID %s, expected genai.Text", article.ID)
	}

	// Parse the numbered list of queries
	lines := strings.Split(string(queriesText), "\n")
	var queries []string
	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}
		// Remove numbering like "1. " or "- "
		line = strings.TrimPrefix(line, "- ")
		if len(line) > 2 && line[1] == '.' && line[0] >= '1' && line[0] <= '9' {
			line = strings.TrimSpace(line[2:])
		}
		if line != "" {
			queries = append(queries, line)
		}
	}

	return queries, nil
}

// GenerateTrendAnalysisPrompt creates a prompt for analyzing trends between current and previous articles
func (c *Client) GenerateTrendAnalysisPrompt(currentTopics []string, previousTopics []string, timeframe string) string {
	currentTopicsStr := strings.Join(currentTopics, ", ")
	previousTopicsStr := strings.Join(previousTopics, ", ")

	return fmt.Sprintf(`Analyze the trends and changes in topics between two time periods:

CURRENT PERIOD (%s):
Topics: %s

PREVIOUS PERIOD:
Topics: %s

Please provide a trend analysis that includes:
1. **New Emerging Topics**: Topics that appeared in current period but not in previous
2. **Declining Topics**: Topics that were prominent before but less so now
3. **Consistent Themes**: Topics that remain important across both periods
4. **Notable Shifts**: Any significant changes in focus or emphasis

Format your response as a brief, insightful analysis (150-200 words) suitable for inclusion in a digest.`,
		timeframe, currentTopicsStr, previousTopicsStr)
}

// AnalyzeSentimentWithEmoji analyzes the sentiment of text and returns score, label, and emoji
func (c *Client) AnalyzeSentimentWithEmoji(text string) (float64, string, string, error) {
	prompt := fmt.Sprintf(`Analyze the sentiment of the following text and respond with EXACTLY this format:

SENTIMENT_SCORE: [number between -1.0 and 1.0, where -1.0 = very negative, 0.0 = neutral, 1.0 = very positive]
SENTIMENT_LABEL: [one word: positive, negative, or neutral]
SENTIMENT_EMOJI: [single emoji that best represents the sentiment]

Text to analyze:
%s

Remember: Respond with EXACTLY the format above, nothing else.`, text)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return 0, "", "", fmt.Errorf("failed to analyze sentiment: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return 0, "", "", fmt.Errorf("no sentiment analysis generated by the API")
	}

	resultPart := resp.Candidates[0].Content.Parts[0]
	resultText, ok := resultPart.(genai.Text)
	if !ok {
		return 0, "", "", fmt.Errorf("unexpected response format from API, expected genai.Text")
	}

	// Parse the response
	lines := strings.Split(string(resultText), "\n")
	var score float64 = 0.0
	var label string = "neutral"
	var emoji string = "üòê"

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if strings.HasPrefix(line, "SENTIMENT_SCORE:") {
			scoreStr := strings.TrimSpace(strings.TrimPrefix(line, "SENTIMENT_SCORE:"))
			if s, err := fmt.Sscanf(scoreStr, "%f", &score); err != nil || s != 1 {
				score = 0.0 // default neutral
			}
		} else if strings.HasPrefix(line, "SENTIMENT_LABEL:") {
			label = strings.TrimSpace(strings.TrimPrefix(line, "SENTIMENT_LABEL:"))
		} else if strings.HasPrefix(line, "SENTIMENT_EMOJI:") {
			emoji = strings.TrimSpace(strings.TrimPrefix(line, "SENTIMENT_EMOJI:"))
		}
	}

	// Clamp score to valid range
	if score < -1.0 {
		score = -1.0
	} else if score > 1.0 {
		score = 1.0
	}

	// Validate label
	if label != "positive" && label != "negative" && label != "neutral" {
		label = "neutral"
	}

	return score, label, emoji, nil
}
