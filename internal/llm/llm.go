package llm

import (
	"briefly/internal/core"
	"context"
	"fmt"
	"math"
	"os" // Added to fetch API key from environment variable
	"strings"
	"time"

	"github.com/google/generative-ai-go/genai"
	"github.com/spf13/viper"
	"google.golang.org/api/option"
)

const (
	// DefaultModel is the default Gemini model to use for summarization.
	DefaultModel = "gemini-2.5-flash-preview-05-20" // Latest Gemini 2.5 Flash Preview
	// DefaultEmbeddingModel is the default model for generating embeddings
	DefaultEmbeddingModel = "text-embedding-004"
	// SummarizeTextPromptTemplate is the template for the summarization prompt.
	SummarizeTextPromptTemplate = "Please summarize the following text concisely:\n\n---\n%s\n---"
	// SummarizeTextWithFormatPromptTemplate is the template for format-aware summarization.
	SummarizeTextWithFormatPromptTemplate = `Please summarize the following text for a %s digest format.

FORMAT GUIDELINES:
- Brief: Create a very concise summary (50-100 words) focusing only on the most essential information
- Standard: Provide a balanced summary (100-200 words) with key points and context
- Detailed: Generate a comprehensive summary (200-300 words) with thorough analysis and context
- Newsletter: Write an engaging summary (150-250 words) in a conversational, shareable style

Please tailor your summary to match the %s format characteristics.

---
%s
---`
)

// Client represents a client for interacting with an LLM.
// It can be expanded to include more configuration or methods.
type Client struct {
	apiKey     string
	modelName  string
	gClient    *genai.Client          // Store the main client
	genaiModel *genai.GenerativeModel // Store the model for reuse
}

// TextGenerationOptions contains options for text generation
type TextGenerationOptions struct {
	MaxTokens   int32   // Maximum number of tokens to generate
	Temperature float32 // Temperature for randomness (0.0 to 1.0)
	Model       string  // Model to use (optional, defaults to client's model)
}

// NewClient creates a new LLM client.
// It supports multiple ways to get the API key (in order of preference):
// 1. Environment variable: GEMINI_API_KEY (or alternatives)
// 2. Viper configuration: gemini.api_key
func NewClient(modelName string) (*Client, error) {
	// Try to get API key from multiple sources for backward compatibility
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		// Try alternative environment variable names
		if apiKey = os.Getenv("GOOGLE_GEMINI_API_KEY"); apiKey == "" {
			if apiKey = os.Getenv("GOOGLE_AI_API_KEY"); apiKey == "" {
				apiKey = viper.GetString("gemini.api_key")
			}
		}
	}
	if apiKey == "" {
		return nil, fmt.Errorf("Gemini API key is required. Set GEMINI_API_KEY environment variable or gemini.api_key in config file.\nGet your API key from: https://makersuite.google.com/app/apikey")
	}

	// Get model name from parameter, viper config, or default
	if modelName == "" {
		modelName = viper.GetString("gemini.model")
		if modelName == "" {
			modelName = DefaultModel
		}
	}

	ctx := context.Background()
	gClient, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return nil, fmt.Errorf("failed to create Gemini client: %w", err)
	}

	model := gClient.GenerativeModel(modelName)

	return &Client{
		apiKey:     apiKey,
		modelName:  modelName,
		gClient:    gClient,
		genaiModel: model,
	}, nil
}

// SummarizeArticleText takes an Article object, extracts its CleanedText,
// and returns a Summary object.
func (c *Client) SummarizeArticleText(article core.Article) (core.Summary, error) {
	if article.CleanedText == "" {
		return core.Summary{}, fmt.Errorf("article ID %s has no CleanedText to summarize", article.ID)
	}

	prompt := fmt.Sprintf(SummarizeTextPromptTemplate, article.CleanedText)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return core.Summary{}, fmt.Errorf("failed to generate content for article ID %s: %w", article.ID, err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return core.Summary{}, fmt.Errorf("no content generated by the API for article ID %s", article.ID)
	}

	summaryPart := resp.Candidates[0].Content.Parts[0]
	summaryText, ok := summaryPart.(genai.Text)
	if !ok {
		return core.Summary{}, fmt.Errorf("unexpected response format from API for article ID %s, expected genai.Text", article.ID)
	}

	// Populate the Summary struct
	// ID for summary can be generated, or based on article ID if 1:1
	// For now, let's assume a new UUID for summary would be generated elsewhere or not strictly needed yet.
	summary := core.Summary{
		// ID: will be set by the caller or a storage layer
		ArticleIDs:  []string{article.ID},
		SummaryText: string(summaryText),
		ModelUsed:   c.modelName,
		// Instructions: Could be the prompt template, or a more abstract description
		Instructions: SummarizeTextPromptTemplate, // Or a reference to it
		// DateGenerated: time.Now().UTC(), // This should be set when the summary is finalized
	}

	return summary, nil
}

// SummarizeArticleTextWithFormat takes an Article object, extracts its CleanedText,
// and returns a Summary object with format-specific guidance.
func (c *Client) SummarizeArticleTextWithFormat(article core.Article, format string) (core.Summary, error) {
	if article.CleanedText == "" {
		return core.Summary{}, fmt.Errorf("article ID %s has no CleanedText to summarize", article.ID)
	}

	prompt := fmt.Sprintf(SummarizeTextWithFormatPromptTemplate, format, format, article.CleanedText)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return core.Summary{}, fmt.Errorf("failed to generate content for article ID %s: %w", article.ID, err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return core.Summary{}, fmt.Errorf("no content generated by the API for article ID %s", article.ID)
	}

	summaryPart := resp.Candidates[0].Content.Parts[0]
	summaryText, ok := summaryPart.(genai.Text)
	if !ok {
		return core.Summary{}, fmt.Errorf("unexpected response format from API for article ID %s, expected genai.Text", article.ID)
	}

	// Populate the Summary struct
	summary := core.Summary{
		ArticleIDs:   []string{article.ID},
		SummaryText:  string(summaryText),
		ModelUsed:    c.modelName,
		Instructions: fmt.Sprintf("Format-aware summarization for %s format", format),
	}

	return summary, nil
}

// SummarizeArticleWithKeyMoments creates a summary with key moments in a specific format
func (c *Client) SummarizeArticleWithKeyMoments(article core.Article) (core.Summary, error) {
	if article.CleanedText == "" {
		return core.Summary{}, fmt.Errorf("article ID %s has no CleanedText to summarize", article.ID)
	}

	// Custom prompt for summary with key moments
	keyMomentsPrompt := `Please analyze the following article and provide a summary in this exact format:

# Executive Summary

[Write a concise 2-3 sentence summary that captures the main topic and key takeaway]

# Key Insights

## 💡 [Short descriptive title for first insight]
> "[Select a powerful, concise quote (1-2 sentences max) from the article]"

**Why it matters:** [One clear sentence explaining the significance]

## 📊 [Short descriptive title for second insight] 
> "[Another impactful quote from the article]"

**Why it matters:** [One clear sentence explaining the significance]

## 🚀 [Short descriptive title for third insight]
> "[Another important quote from the article]"

**Why it matters:** [One clear sentence explaining the significance]

## 🔍 [Short descriptive title for fourth insight]
> "[Final key quote from the article]"

**Why it matters:** [One clear sentence explaining the significance]

Instructions:
- Use EXACT, concise quotes (1-2 sentences maximum) from the article
- Create descriptive titles that categorize each insight (e.g., "Performance Breakthrough", "New Feature Launch", "Market Impact")
- Keep explanations to one clear, punchy sentence
- Use appropriate emojis for insight categories: 💡 (concepts), 📊 (data/metrics), 🚀 (launches/features), 🔍 (analysis), ⚡ (speed/performance), 🔒 (security/privacy), 💰 (business/cost)
- Select 3-4 most impactful moments that represent different aspects of the story

Article Content:
%s`

	prompt := fmt.Sprintf(keyMomentsPrompt, article.CleanedText)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return core.Summary{}, fmt.Errorf("failed to generate content for article ID %s: %w", article.ID, err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return core.Summary{}, fmt.Errorf("no content generated by the API for article ID %s", article.ID)
	}

	summaryPart := resp.Candidates[0].Content.Parts[0]
	summaryText, ok := summaryPart.(genai.Text)
	if !ok {
		return core.Summary{}, fmt.Errorf("unexpected response format from API for article ID %s, expected genai.Text", article.ID)
	}

	// Create the Summary object
	summary := core.Summary{
		ArticleIDs:    []string{article.ID},
		SummaryText:   string(summaryText),
		ModelUsed:     c.modelName,
		Instructions:  "Article summarization with key moments and explanations",
		DateGenerated: time.Now().UTC(),
	}

	return summary, nil
}

// Close cleans up resources used by the client
func (c *Client) Close() {
	if c.gClient != nil {
		if err := c.gClient.Close(); err != nil {
			// Log error but don't return it since Close() should be idempotent
			fmt.Printf("Warning: failed to close LLM client: %s\n", err)
		}
	}
}

// GetGenaiModel returns the underlying genai model for direct use by other packages
func (c *Client) GetGenaiModel() *genai.GenerativeModel {
	return c.genaiModel
}

// GenerateText generates text using the LLM with specified options
func (c *Client) GenerateText(ctx context.Context, prompt string, options TextGenerationOptions) (string, error) {
	if prompt == "" {
		return "", fmt.Errorf("prompt cannot be empty")
	}

	// Create a model instance with options
	model := c.genaiModel
	if options.Model != "" && options.Model != c.modelName {
		// Create a new model instance for different model
		var err error
		model = c.gClient.GenerativeModel(options.Model)
		if err != nil {
			return "", fmt.Errorf("failed to create model %s: %w", options.Model, err)
		}
	}

	// Set generation config if options are provided
	if options.MaxTokens > 0 || options.Temperature > 0 {
		config := &genai.GenerationConfig{}
		if options.MaxTokens > 0 {
			config.MaxOutputTokens = &options.MaxTokens
		}
		if options.Temperature > 0 {
			config.Temperature = &options.Temperature
		}
		model.GenerationConfig = *config
	}

	// Generate content
	resp, err := model.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate text: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("empty response from LLM")
	}

	contentPart := resp.Candidates[0].Content.Parts[0]
	content, ok := contentPart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API, expected genai.Text")
	}

	return string(content), nil
}

// GenerateSummary is a simpler function, more aligned with the original request,
// that takes text and returns a summary string.
// It uses the GEMINI_API_KEY environment variable and the default model.
func GenerateSummary(textContent string) (string, error) {
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		return "", fmt.Errorf("GEMINI_API_KEY environment variable not set")
	}

	ctx := context.Background()
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return "", fmt.Errorf("failed to create Gemini client: %w", err)
	}
	defer func() { _ = client.Close() }()

	model := client.GenerativeModel(DefaultModel)
	prompt := fmt.Sprintf(SummarizeTextPromptTemplate, textContent)

	resp, err := model.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate content for summarization: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no content generated by the API for summarization")
	}

	summaryPart := resp.Candidates[0].Content.Parts[0]
	summary, ok := summaryPart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for summarization, expected genai.Text")
	}

	return string(summary), nil
}

// RegenerateDigestWithMyTake takes an existing digest and a personal take,
// then uses the LLM to regenerate the entire digest incorporating the personal perspective throughout
func RegenerateDigestWithMyTake(digestContent, myTake, format string) (string, error) {
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		return "", fmt.Errorf("GEMINI_API_KEY environment variable not set")
	}

	ctx := context.Background()
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return "", fmt.Errorf("failed to create Gemini client: %w", err)
	}
	defer func() { _ = client.Close() }()

	model := client.GenerativeModel(DefaultModel)

	// Create a sophisticated prompt that asks the LLM to rewrite the digest
	// incorporating the personal perspective throughout
	prompt := fmt.Sprintf(`You are helping to rewrite a digest to incorporate the author's personal perspective throughout the content. 

Here is the original digest:
---
%s
---

Here is the author's personal take/perspective:
---
%s
---

Please rewrite the entire digest incorporating the author's personal voice and perspective throughout. The goal is to:

1. Maintain all the factual information and structure from the original digest
2. Weave the author's perspective naturally throughout the content (not just at the end)
3. Use the author's voice and tone based on their "take"
4. Keep the same format (%s) but make it feel like the author wrote it with their personal insights
5. Make it feel cohesive and natural, not like separate sections were bolted together
6. Preserve any important details, links, and key insights from the original
7. The result should feel like the author's personal commentary and analysis of the topics

Do not add a separate "My Take" section - instead, integrate the perspective throughout the entire digest naturally.

Please provide the complete rewritten digest:`, digestContent, myTake, format)

	resp, err := model.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate content for digest regeneration: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no content generated by the API for digest regeneration")
	}

	contentPart := resp.Candidates[0].Content.Parts[0]
	content, ok := contentPart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for digest regeneration, expected genai.Text")
	}

	return string(content), nil
}

// GeneratePromptCorner generates interesting prompts based on digest content
// that readers can copy and use with any LLM (ChatGPT, Gemini, Claude, etc.)
func GeneratePromptCorner(digestContent string) (string, error) {
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		return "", fmt.Errorf("GEMINI_API_KEY environment variable not set")
	}

	ctx := context.Background()
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return "", fmt.Errorf("failed to create Gemini client: %w", err)
	}
	defer func() { _ = client.Close() }()

	model := client.GenerativeModel(DefaultModel)

	prompt := fmt.Sprintf(`Based on the following digest content, create at most 3 interesting and practical prompts that readers can copy and paste into any LLM (ChatGPT, Gemini, Claude, etc.). 

The prompts should be:
- Directly inspired by the topics covered in the digest
- Practical and actionable for developers, tech professionals, or curious learners
- Self-contained (no need for additional context)
- Simple to copy and paste
- Encouraging exploration and learning

Format the output as a clean markdown section with:
- A brief intro sentence
- Each prompt in a code block for easy copying
- A short description after each prompt explaining what it's for

Here's the digest content:
---
%s
---

Please generate the Prompt Corner section:`, digestContent)

	resp, err := model.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate content for prompt corner: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no content generated by the API for prompt corner")
	}

	contentPart := resp.Candidates[0].Content.Parts[0]
	content, ok := contentPart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for prompt corner, expected genai.Text")
	}

	return string(content), nil
}

// GenerateDigestTitle creates a compelling Smart Headline for a digest based on the content
func (c *Client) GenerateDigestTitle(digestContent string, format string) (string, error) {
	if digestContent == "" {
		return "", fmt.Errorf("cannot generate title for empty digest content")
	}

	// Create a prompt that asks for a compelling Smart Headline based on the digest content
	prompt := fmt.Sprintf(`Generate a compelling Smart Headline for the following digest content. This headline will be the main title of the digest and should capture readers' attention while accurately representing the content.

REQUIREMENTS:
- Must be under 80 characters
- Should capture the core themes, insights, or trends from the content
- Be engaging and informative to encourage reading
- Avoid generic words like "Update", "News", or "Summary"
- Focus on the most impactful or surprising element from the content
- Align with '%s' format style:
  * Brief: Direct and action-oriented
  * Standard: Clear and informative
  * Detailed: Analytical and comprehensive
  * Newsletter: Engaging and shareable
  * Email: Personal and relevant

DIGEST CONTENT:
---
%s
---

Generate only the Smart Headline text, without quotes or additional formatting:`, format, digestContent)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate title: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no title generated by the API")
	}

	titlePart := resp.Candidates[0].Content.Parts[0]
	title, ok := titlePart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for title generation, expected genai.Text")
	}

	// Clean up the title - remove any unwanted characters or formatting
	titleStr := strings.TrimSpace(string(title))
	titleStr = strings.Trim(titleStr, "\"'") // Remove quotes if present

	return titleStr, nil
}

// GenerateDigestTitle creates a compelling Smart Headline for a digest based on the content
// It uses the GEMINI_API_KEY environment variable and the default model.
func GenerateDigestTitle(digestContent string, format string) (string, error) {
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		return "", fmt.Errorf("GEMINI_API_KEY environment variable not set")
	}

	ctx := context.Background()
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return "", fmt.Errorf("failed to create Gemini client: %w", err)
	}
	defer func() { _ = client.Close() }()

	model := client.GenerativeModel(DefaultModel)

	// Create a prompt that asks for a compelling Smart Headline based on the digest content
	prompt := fmt.Sprintf(`Generate a compelling Smart Headline for the following digest content. This headline will be the main title of the digest and should capture readers' attention while accurately representing the content.

REQUIREMENTS:
- Must be under 80 characters
- Should capture the core themes, insights, or trends from the content
- Be engaging and informative to encourage reading
- Avoid generic words like "Update", "News", or "Summary"
- Focus on the most impactful or surprising element from the content
- Align with '%s' format style:
  * Brief: Direct and action-oriented
  * Standard: Clear and informative
  * Detailed: Analytical and comprehensive
  * Newsletter: Engaging and shareable
  * Email: Personal and relevant

DIGEST CONTENT:
---
%s
---

Generate only the Smart Headline text, without quotes or additional formatting:`, format, digestContent)

	resp, err := model.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate title: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no title generated by the API")
	}

	titlePart := resp.Candidates[0].Content.Parts[0]
	title, ok := titlePart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for title generation, expected genai.Text")
	}

	// Clean up the title - remove any unwanted characters or formatting
	titleStr := strings.TrimSpace(string(title))
	titleStr = strings.Trim(titleStr, "\"'") // Remove quotes if present

	return titleStr, nil
}

// GenerateEmbedding generates a vector embedding for the given text using Gemini's embedding model
func (c *Client) GenerateEmbedding(text string) ([]float64, error) {
	ctx := context.Background()

	// Use the embedding model specifically for embeddings
	embeddingModel := c.gClient.EmbeddingModel(DefaultEmbeddingModel)

	resp, err := embeddingModel.EmbedContent(ctx, genai.Text(text))
	if err != nil {
		return nil, fmt.Errorf("failed to generate embedding: %w", err)
	}

	if resp.Embedding == nil || resp.Embedding.Values == nil {
		return nil, fmt.Errorf("no embedding values returned from API")
	}

	// Convert float32 to float64
	embedding := make([]float64, len(resp.Embedding.Values))
	for i, val := range resp.Embedding.Values {
		embedding[i] = float64(val)
	}

	return embedding, nil
}

// GenerateEmbeddingForArticle generates an embedding for an article's content
func (c *Client) GenerateEmbeddingForArticle(article core.Article) ([]float64, error) {
	// Combine title and content for better embedding representation
	text := article.Title + "\n\n" + article.CleanedText

	// Truncate if text is too long (embedding models have token limits)
	if len(text) > 8000 { // Conservative limit for text-embedding-004
		text = text[:8000]
	}

	return c.GenerateEmbedding(text)
}

// GenerateEmbeddingForSummary generates an embedding for a summary's content
func (c *Client) GenerateEmbeddingForSummary(summary core.Summary) ([]float64, error) {
	return c.GenerateEmbedding(summary.SummaryText)
}

// CosineSimilarity calculates the cosine similarity between two embeddings
func CosineSimilarity(a, b []float64) float64 {
	if len(a) != len(b) {
		return 0
	}

	var dotProduct, normA, normB float64
	for i := range a {
		dotProduct += a[i] * b[i]
		normA += a[i] * a[i]
		normB += b[i] * b[i]
	}

	if normA == 0 || normB == 0 {
		return 0
	}

	return dotProduct / (math.Sqrt(normA) * math.Sqrt(normB))
}

// GenerateResearchQueries generates search queries for deep research based on article content
func (c *Client) GenerateResearchQueries(article core.Article, depth int) ([]string, error) {
	if article.CleanedText == "" {
		return nil, fmt.Errorf("article ID %s has no CleanedText for research query generation", article.ID)
	}

	prompt := fmt.Sprintf(`Based on the following article, generate %d highly specific and targeted search queries that would help discover related content, background information, and follow-up research. 

The queries should be:
- Specific enough to find relevant, high-quality sources
- Diverse in perspective (technical, business, historical, competitive analysis)
- Actionable for someone researching this topic further
- Not too broad or generic

Article Title: %s

Article Content:
%s

Return the queries as a simple numbered list (1. Query one 2. Query two, etc.) without any additional formatting:`, depth, article.Title, article.CleanedText)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return nil, fmt.Errorf("failed to generate research queries for article ID %s: %w", article.ID, err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return nil, fmt.Errorf("no queries generated by the API for article ID %s", article.ID)
	}

	queriesPart := resp.Candidates[0].Content.Parts[0]
	queriesText, ok := queriesPart.(genai.Text)
	if !ok {
		return nil, fmt.Errorf("unexpected response format from API for article ID %s, expected genai.Text", article.ID)
	}

	// Parse the numbered list of queries
	lines := strings.Split(string(queriesText), "\n")
	var queries []string
	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}
		// Remove numbering like "1. " or "- "
		line = strings.TrimPrefix(line, "- ")
		if len(line) > 2 && line[1] == '.' && line[0] >= '1' && line[0] <= '9' {
			line = strings.TrimSpace(line[2:])
		}
		if line != "" {
			queries = append(queries, line)
		}
	}

	return queries, nil
}

// GenerateTrendAnalysisPrompt creates a prompt for analyzing trends between current and previous articles
func (c *Client) GenerateTrendAnalysisPrompt(currentTopics []string, previousTopics []string, timeframe string) string {
	currentTopicsStr := strings.Join(currentTopics, ", ")
	previousTopicsStr := strings.Join(previousTopics, ", ")

	return fmt.Sprintf(`Analyze the trends and changes in topics between two time periods:

CURRENT PERIOD (%s):
Topics: %s

PREVIOUS PERIOD:
Topics: %s

Please provide a trend analysis that includes:
1. **New Emerging Topics**: Topics that appeared in current period but not in previous
2. **Declining Topics**: Topics that were prominent before but less so now
3. **Consistent Themes**: Topics that remain important across both periods
4. **Notable Shifts**: Any significant changes in focus or emphasis

Format your response as a brief, insightful analysis (150-200 words) suitable for inclusion in a digest.`,
		timeframe, currentTopicsStr, previousTopicsStr)
}

// GenerateFinalDigest creates a comprehensive digest summary from multiple article summaries
func (c *Client) GenerateFinalDigest(combinedSummaries, format string) (string, error) {
	if combinedSummaries == "" {
		return "", fmt.Errorf("cannot generate digest from empty summaries")
	}

	// Create format-specific style requirements
	var styleRequirements string
	switch format {
	case "brief":
		styleRequirements = "Concise and to-the-point (150-300 words total). Focus only on the most essential insights."
	case "standard":
		styleRequirements = "Balanced and informative (300-500 words). Include key points with sufficient context."
	case "detailed":
		styleRequirements = "Comprehensive and analytical (500-800 words). Provide thorough analysis and deeper insights."
	case "newsletter":
		styleRequirements = "Engaging and shareable (400-600 words). Use a conversational tone with compelling insights."
	case "email":
		styleRequirements = "Personal and relevant (300-500 words). Write as if addressing a colleague directly."
	default:
		styleRequirements = "Clear and informative. Include key points with sufficient context."
	}

	// Create a comprehensive prompt for digest generation based on format
	prompt := fmt.Sprintf(`You are creating a comprehensive digest summary that synthesizes multiple article summaries into a cohesive, engaging overview.

FORMAT: %s
STYLE REQUIREMENTS for %s format:
%s

Your task is to:
1. Read through all the individual article summaries
2. Identify the key themes, trends, and insights across all articles
3. Create a cohesive narrative that connects the articles
4. Highlight the most important takeaways and implications
5. Write in a %s style that matches the format requirements above
6. INCLUDE CITATIONS: When referencing specific insights or information from articles, include citations in the format [1], [2], etc., corresponding to the numbered articles provided

INDIVIDUAL ARTICLE SUMMARIES:
---
%s
---

Please generate a comprehensive digest summary that weaves these articles together into a compelling, unified narrative. Focus on:
- Overarching themes and patterns
- Key insights and implications
- How the articles relate to and complement each other
- Most important takeaways for readers
- Future implications or trends

CITATION REQUIREMENTS:
- Use numbered citations [1], [2], [3], etc. when referencing specific articles
- Place citations immediately after claims, insights, or information from specific sources
- Ensure every significant point is properly attributed to maintain credibility and transparency
- The citation numbers should correspond to the article numbers in the summaries above

Generate the final digest content with proper citations:`, format, format, styleRequirements, format, combinedSummaries)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("failed to generate final digest: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no digest content generated by the API")
	}

	digestPart := resp.Candidates[0].Content.Parts[0]
	digestText, ok := digestPart.(genai.Text)
	if !ok {
		return "", fmt.Errorf("unexpected response format from API for digest generation, expected genai.Text")
	}

	return string(digestText), nil
}

// AnalyzeSentimentWithEmoji analyzes the sentiment of text and returns score, label, and emoji
func (c *Client) AnalyzeSentimentWithEmoji(text string) (float64, string, string, error) {
	prompt := fmt.Sprintf(`Analyze the sentiment of the following text and respond with EXACTLY this format:

SENTIMENT_SCORE: [number between -1.0 and 1.0, where -1.0 = very negative, 0.0 = neutral, 1.0 = very positive]
SENTIMENT_LABEL: [one word: positive, negative, or neutral]
SENTIMENT_EMOJI: [single emoji that best represents the sentiment]

Text to analyze:
%s

Remember: Respond with EXACTLY the format above, nothing else.`, text)

	ctx := context.Background()
	resp, err := c.genaiModel.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return 0, "", "", fmt.Errorf("failed to analyze sentiment: %w", err)
	}

	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return 0, "", "", fmt.Errorf("no sentiment analysis generated by the API")
	}

	resultPart := resp.Candidates[0].Content.Parts[0]
	resultText, ok := resultPart.(genai.Text)
	if !ok {
		return 0, "", "", fmt.Errorf("unexpected response format from API, expected genai.Text")
	}

	// Parse the response
	lines := strings.Split(string(resultText), "\n")
	var score = 0.0
	var label = "neutral"
	var emoji = "😐"

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if strings.HasPrefix(line, "SENTIMENT_SCORE:") {
			scoreStr := strings.TrimSpace(strings.TrimPrefix(line, "SENTIMENT_SCORE:"))
			if s, err := fmt.Sscanf(scoreStr, "%f", &score); err != nil || s != 1 {
				score = 0.0 // default neutral
			}
		} else if strings.HasPrefix(line, "SENTIMENT_LABEL:") {
			label = strings.TrimSpace(strings.TrimPrefix(line, "SENTIMENT_LABEL:"))
		} else if strings.HasPrefix(line, "SENTIMENT_EMOJI:") {
			emoji = strings.TrimSpace(strings.TrimPrefix(line, "SENTIMENT_EMOJI:"))
		}
	}

	// Clamp score to valid range
	if score < -1.0 {
		score = -1.0
	} else if score > 1.0 {
		score = 1.0
	}

	// Validate label
	if label != "positive" && label != "negative" && label != "neutral" {
		label = "neutral"
	}

	return score, label, emoji, nil
}
